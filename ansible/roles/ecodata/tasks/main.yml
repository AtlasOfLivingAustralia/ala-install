- include: ../../common/tasks/setfacts.yml
  tags:
    - ecodata
    - deploy
    - properties
    - cron

- name: set ecodata_user as default value
  set_fact:
    ecodata_user: "{{ (exec_jar) | ternary ('ecodata', 'tomcat7')}}"
  tags:
    - ecodata
    - deploy
    - properties
    - cron

- name: "Create system user for ecodata"
  user:
    name: "{{ ecodata_user }}"
    state: present
    system: yes
  tags:
    - service

- name: Ensure group for the backup user exists
  ansible.builtin.group:
    name: "{{ecodata_backup_user}}"
    state: present

- name: create the user used for backups
  user:
    name: "{{ecodata_backup_user}}"
    state: present
    system: yes
    groups:
      - "{{ecodata_backup_user}}"
      - "{{ecodata_user}}"
  tags:
    - cron

#
# External configuration directories and files
#
- name: ensure target directories exist [data subdirectories etc.]
  file: path={{item}} state=directory owner='mongodb' group='mongodb'
  with_items:
    - "{{data_dir}}/mongodb"
  tags:
    - properties
    - ecodata

- name: add jar and service
  include_role:
    name: exec-jar
  vars:
    service_name: "ecodata"
    jar_url: '{{ ecodata_artifact_url }}'
    extra_params:
      - key: "java.io.tmpdir"
        value: "{{data_dir}}/tmp"
  tags:
    - deploy
    - service
    - ecodata
  when: exec_jar

- name: ensure target directories exist [data subdirectories etc.]
  file: path={{item}} state=directory owner={{ecodata_user}} group={{ecodata_user}}
  with_items:
    - "{{data_dir}}/ecodata/config"
    - "{{data_dir}}/ecodata/uploads"
    - "{{data_dir}}/ecodata/models"
    - "{{data_dir}}/ecodata/elasticsearch"
    - "{{data_dir}}/ecodata/scripts"
    - "{{data_dir}}/tmp"
  tags:
    - properties
    - ecodata

- name: copy all config.properties
  template: src={{ecodata_properties_file | default('ecodata-config.properties')}} dest={{data_dir}}/ecodata/config/ecodata-config.properties
  tags:
    - properties
    - ecodata

- name: copy logback config
  template:
    src: "{{item}}"
    dest: "{{data_dir}}/ecodata/config/{{item}}"
    owner: "{{ecodata_user}}"
    group: "{{ecodata_user}}"
  with_items:
    - logback.groovy
    - logback.xml
  notify:
    - restart ecodata
  tags:
    - properties
    - ecodata
  when: exec_jar

- name: ensure ecodata log directory exists
  file: path={{item}} state=directory owner={{ecodata_user}} group={{ecodata_user}}
  with_items:
    - "/var/log/atlas/ecodata"
  tags:
    - properties
    - ecodata
  when: exec_jar

- name: set ecodata log ownership
  file: path=/var/log/atlas/ecodata owner='{{ecodata_user}}' group='{{ecodata_user}}' recurse=true
  notify:
    - restart ecodata
  tags:
    - properties
    - ecodata
  when: exec_jar

#
# Copy sensitive data xml file
#
- name: Copy config files to config directory
  copy: src=sensitive-species-data.xml dest={{data_dir}}/ecodata/config/sensitive-species-data.xml
  tags:
    - ecodata
    - properties

#
# Copy default/example models files.  Don't override if already present
# as the versions in ansible are quick start for new installations.
#
- name: Copy models files to config directory
  copy: src=models/ dest={{data_dir}}/ecodata/models/ force=no
  tags:
    - ecodata
    - properties

- name: Create backup path if it doesn't exist
  file: path="{{data_dir}}/backups" owner="{{ecodata_backup_user}}" group="{{ecodata_backup_user}}" recurse=true mode='u=rwX,g=rwX,o-rwx'
  tags:
    - cron

- name: Install jq command line json processor
  apt: pkg="jq" state=present
  tags:
    - ecodata
    - properties
    - jq

- name: Copy scripts to scripts directory
  template:
    src: "{{ item }}"
    dest: "{{data_dir}}/ecodata/scripts/{{item}}"
    owner: "{{ecodata_user}}"
    group: "{{ecodata_user}}"
    mode: "u+rx,g+r,o-rxw"
  with_items:
    - accessToken.sh
    - replicaSetConfig.sh
    - replicaSetStatus.sh
    - runProjectDownload.sh
    - reIndexAll.sh
    - runMuDownload.sh
    - runOrgDownload.sh
    - scheduledDAWEDownloads.sh
  tags:
    - ecodata
    - properties

- name: Copy scripts to scripts directory
  template:
    src: "{{ item }}"
    dest: "{{data_dir}}/ecodata/scripts/{{item}}"
    owner: "{{ecodata_backup_user}}"
    group: "{{ecodata_backup_user}}"
    mode: "u+rx,g+r,o-rxw"
  with_items:
    - backup-ecodata.sh
  tags:
    - ecodata
    - properties

- name: Copy scripts to scripts directory
  template:
    src: "{{ item }}"
    dest: "{{data_dir}}/ecodata/scripts/{{item}}"
    owner: "{{ecodata_backup_user}}"
    group: "{{ecodata_backup_user}}"
    mode: "u+rx,g+r,o-rxw"
  with_items:
    - copyProdData.sh
  tags:
    - cron
  when: scheduled_production_data_copy

- name: Copy scripts that copy and restore production data (not for use on production hosts)
  template:
    src: "{{ item }}"
    dest: "{{data_dir}}/ecodata/scripts/{{item}}"
    owner: "{{ecodata_user}}"
    group: "{{ecodata_user}}"
    mode: "u+rx,g+r,o-rxw"
  with_items:
      - syncProdData.sh
      - copyProdDocuments.sh
  tags:
    - cron
  when: scheduled_production_data_load or scheduled_production_documents_copy


- name: set data ownership
  file: path={{data_dir}}/ecodata/{{item}} owner='{{ecodata_user}}' group='{{ecodata_user}}' recurse=true mode='u=rwX,g=rX,o-rxw'
  with_items:
    - config
    - models
    - elasticsearch
  tags:
    - properties
    - ecodata

- name: set uploads ownership so they can be served by nginx
  file: path={{data_dir}}/ecodata/{{item}} owner='{{ecodata_user}}' group='{{ecodata_user}}' recurse=true mode='u=rwX,g=rX,o=rX'
  with_items:
    - uploads
  tags:
    - properties
    - ecodata

#
# WAR file deployment and virtual host configuration
#
- include: ../../apache_vhost/tasks/main.yml context_path='{{ ecodata_context_path }}' hostname='{{ ecodata_hostname }}'
  tags:
    - deploy
    - apache_vhost
    - ecodata
  when: not webserver_nginx

- name: set nginx proxy target if configured
  set_fact:
    ecodata_proxy_target: "{{ecodata_context_path}}"
  tags:
    - nginx_vhost
    - deploy
    - ecodata
  when: webserver_nginx and ecodata_proxy_target is not defined

- name: add nginx vhost to proxy to grails and reporting server
  include_role:
    name: nginx_vhost
  vars:
    appname: "ecodata"
    hostname: "{{ ecodata_hostname }}"
    context_path: "{{ ecodata_context_path }}"
    tomcat_server_port: "{{ ecodata_server_port }}"
    nginx_paths:
      - path: "{{ecodata_proxy_target}}/ws/document/download"
        sort_label: "1_upload"
        is_proxy: false
        alias: "{{ upload_dir | default('/data/ecodata/uploads') }}"
      - path: "{{ecodata_proxy_target}}/document/download"
        sort_label: "2_upload"
        is_proxy: false
        alias: "{{ upload_dir | default('/data/ecodata/uploads') }}"
      - path: "{{ecodata_context_path}}"
        sort_label: "2_ws"
        is_proxy: true
        proxy_pass: "http://127.0.0.1:{{ ecodata_server_port }}{{ecodata_proxy_target}}"
      - path: "{{ecodata_context_path}}/ws/search/downloadAllData"
        sort_label: "2_ws_downloads"
        is_proxy: true
        add_header: "{{download_header}} {{ ecodata_url }}"
        proxy_hostname: "{{ ecodata_reporting_hostname | default(ecodata_hostname) }}"
        proxy_pass: "{{ ecodata_reporting_server if ecodata_reporting_server is defined else 'http://127.0.0.1:' + ecodata_server_port }}{{ecodata_proxy_target}}/ws/search/downloadAllData"
      - path: "{{ecodata_context_path}}/ws/search/downloadUserList"
        sort_label: "3_downloadUserList"
        is_proxy: true
        proxy_hostname: "{{ ecodata_reporting_hostname | default(ecodata_hostname) }}"
        proxy_pass: "{{ ecodata_reporting_server if ecodata_reporting_server is defined else 'http://127.0.0.1:' + ecodata_server_port }}{{ecodata_proxy_target}}/ws/search/downloadUserList"
      - path: "{{ecodata_context_path}}/ws/search/downloadOrganisationData"
        sort_label: "4_downloadOrganisationData"
        is_proxy: true
        proxy_hostname: "{{ ecodata_reporting_hostname | default(ecodata_hostname) }}"
        proxy_pass: "{{ ecodata_reporting_server if ecodata_reporting_server is defined else 'http://127.0.0.1:' + ecodata_server_port }}{{ecodata_proxy_target}}/ws/search/downloadOrganisationData"
      - path: "{{ecodata_context_path}}/ws/search/downloadProjectData"
        sort_label: "5_downloadProjectData"
        is_proxy: true
        proxy_hostname: "{{ ecodata_reporting_hostname | default(ecodata_hostname) }}"
        proxy_pass: "{{ ecodata_reporting_server if ecodata_reporting_server is defined else 'http://127.0.0.1:' + ecodata_server_port }}{{ecodata_proxy_target}}/ws/search/downloadProjectData"
      - path: "{{ecodata_context_path}}/ws/search/downloadShapefile"
        sort_label: "6_downloadShapefile"
        is_proxy: true
        proxy_hostname: "{{ ecodata_reporting_hostname | default(ecodata_hostname) }}"
        proxy_pass: "{{ ecodata_reporting_server if ecodata_reporting_server is defined else 'http://127.0.0.1:' + ecodata_server_port }}{{ecodata_proxy_target}}/ws/search/downloadShapefile"
      - path: "{{ecodata_context_path}}/ws/search/downloadProjectDataFile/"
        sort_label: "7_ws_downloads_project_data"
        is_proxy: true
        proxy_hostname: "{{ ecodata_reporting_hostname | default(ecodata_hostname) }}"
        proxy_pass: "{{ ecodata_reporting_server if ecodata_reporting_server is defined else 'http://127.0.0.1:' + ecodata_server_port }}{{ecodata_proxy_target}}/ws/search/downloadProjectDataFile/"
#        TODO: remove once https://github.com/AtlasOfLivingAustralia/fieldcapture/issues/3004 is deployed to production
      - path: "{{ecodata_context_path}}/ws/managementunit/getReportPeriods/"
        sort_label: "8_ws_mu_periods"
        is_proxy: true
        proxy_hostname: "{{ ecodata_reporting_hostname | default(ecodata_hostname) }}"
        proxy_pass: "{{ ecodata_reporting_server if ecodata_reporting_server is defined else 'http://127.0.0.1:' + ecodata_server_port }}{{ecodata_proxy_target}}/ws/managementunit/getReportPeriods/"
      - path: "{{ecodata_context_path}}/ws/managementunit/generateReportsInPeriod/"
        sort_label: "9_ws_mu_report"
        is_proxy: true
        proxy_hostname: "{{ ecodata_reporting_hostname | default(ecodata_hostname) }}"
        proxy_pass: "{{ ecodata_reporting_server if ecodata_reporting_server is defined else 'http://127.0.0.1:' + ecodata_server_port }}{{ecodata_proxy_target}}/ws/managementunit/generateReportsInPeriod/"
      - path: "{{ecodata_context_path}}/ws/download/"
        sort_label: "10_ws_download"
        is_proxy: true
        proxy_hostname: "{{ ecodata_reporting_hostname | default(ecodata_hostname) }}"
        proxy_pass: "{{ ecodata_reporting_server if ecodata_reporting_server is defined else 'http://127.0.0.1:' + ecodata_server_port }}{{ecodata_proxy_target}}/ws/download/"
      - path: "{{ecodata_context_path}}/ws/report/generateReportsInPeriod/"
        sort_label: "11_ws_mu_report"
        is_proxy: true
        proxy_hostname: "{{ ecodata_reporting_hostname | default(ecodata_hostname) }}"
        proxy_pass: "{{ ecodata_reporting_server if ecodata_reporting_server is defined else 'http://127.0.0.1:' + ecodata_server_port }}{{ecodata_proxy_target}}/ws/report/generateReportsInPeriod/"

      - path: "{{ ecodata_context_path }}/ws/geoServer/wms"
        sort_label: "geo_server_wms"
        is_proxy: true
        proxy_hostname: "{{ ecodata_reporting_hostname | default(ecodata_hostname) }}"
        proxy_pass: "{{ ecodata_reporting_server if ecodata_reporting_server is defined else 'http://127.0.0.1:' + ecodata_server_port }}{{ecodata_proxy_target}}/ws/geoServer/wms"
      - path: "{{ ecodata_context_path }}/ws/geoServer/createStyle"
        sort_label: "geo_server_create_style"
        is_proxy: true
        proxy_hostname: "{{ ecodata_reporting_hostname | default(ecodata_hostname) }}"
        proxy_pass: "{{ ecodata_reporting_server if ecodata_reporting_server is defined else 'http://127.0.0.1:' + ecodata_server_port }}{{ecodata_proxy_target}}/ws/geoServer/createStyle"
      - path: "{{ ecodata_context_path }}/ws/geoServer/getLayerName"
        sort_label: "geo_server_layer_name"
        is_proxy: true
        proxy_hostname: "{{ ecodata_reporting_hostname | default(ecodata_hostname) }}"
        proxy_pass: "{{ ecodata_reporting_server if ecodata_reporting_server is defined else 'http://127.0.0.1:' + ecodata_server_port }}{{ecodata_proxy_target}}/ws/geoServer/getLayerName"
  tags:
    - nginx_vhost
    - deploy
    - ecodata
  when: webserver_nginx and use_reporting_server

- name: add nginx vhost to proxy to grails
  include_role:
    name: nginx_vhost
  vars:
    appname: "ecodata"
    hostname: "{{ ecodata_hostname }}"
    context_path: "{{ ecodata_context_path }}"
    tomcat_server_port: "{{ ecodata_server_port }}"
    nginx_paths:
      - path: "{{ecodata_proxy_target}}/ws/document/download"
        sort_label: "1_upload"
        is_proxy: false
        alias: "{{ upload_dir | default('/data/ecodata/uploads') }}"
      - path: "{{ecodata_proxy_target}}/document/download"
        sort_label: "2_upload"
        is_proxy: false
        alias: "{{ upload_dir | default('/data/ecodata/uploads') }}"
      - path: "{{ecodata_context_path}}"
        sort_label: "2_ws"
        is_proxy: true
        proxy_pass: "http://127.0.0.1:{{ ecodata_server_port }}{{ecodata_proxy_target}}"

  when: webserver_nginx and not use_reporting_server
  tags:
    - nginx_vhost

- name: Configure the /uploads location to be only accessible from MERIT and BioCollect
  blockinfile:
    dest: /etc/nginx/sites-available/{{ecodata_hostname}}.conf
    insertafter: "location {{item.loc}}"
    block: |
      allow 127.0.0.1;
      allow {{ merit_ip }};
      allow {{ biocollect_ip }};
      allow {{ mongo_secondary_ip | default('127.0.0.1') }};
      deny all;
      expires 1y;
    marker_begin: "BEGIN_{{item.mark}}"
    marker_end: "END_{{item.mark}}"
  loop:
    - { mark: '1', loc: '/ws/document/download' }
    - { mark: '2', loc: '/document/download' }
  tags:
    - nginx_vhost_block

- include: ../../tomcat_deploy/tasks/main.yml war_url='{{ ecodata_war_url }}' context_path='{{ecodata_context_path}}' hostname='{{ ecodata_hostname }}'
  tags:
    - deploy
    - tomcat_vhost
    - ecodata
  when: not exec_jar

#
# Override the default memory settings for Tomcat to increase heap space and change the garbage collector
#
- name: Override default tomcat memory configuration
  lineinfile:
    dest={{tomcat_conf}}
    regexp="^JAVA_OPTS"
    line='JAVA_OPTS="{{tomcat_java_opts_override}}"'
  notify:
    - restart tomcat
  tags:
    - ecodata
    - deploy
    - tomcat
  when: not exec_jar

#
# Cron Job configuration
#
- name: Allow ecodatabackup to configure cron
  lineinfile:
    path: /etc/cron.allow
    line: "{{ecodata_backup_user}}"
    create: yes
  tags:
    - cron
  when: scheduled_database_backup or scheduled_production_data_copy or scheduled_downloads

- name: Schedule cron job to backup ecodata
  cron: minute=13 hour=4 name="Backup ecodata database" job="{{data_dir}}/ecodata/scripts/backup-ecodata.sh >/dev/null 2>&1" user={{ecodata_backup_user}} state=present
  tags:
    - cron
  when: scheduled_database_backup

- name: install cron job for indexing elastic search
  cron: minute=0 hour=6 weekday=0 name="Elastic search indexing" job="{{data_dir}}/ecodata/scripts/reIndexAll.sh >/dev/null 2>&1" user=root state=present
  tags:
    - cron
  when: scheduled_re_index

- name: Schedule cron job to load production data into the staging server
  cron: minute=1 hour=5 weekday=0 name="Load production data" job="{{data_dir}}/ecodata/scripts/syncProdData.sh >/dev/null 2>&1" user=root state=present
  tags:
    - cron
  when: scheduled_production_data_load

- name: Schedule cron job to copy data from the production server
  cron: minute=1 hour=6 name="Copy data from the production server" job="{{data_dir}}/ecodata/scripts/copyProdData.sh >/dev/null 2>&1" user="{{ecodata_backup_user}}" state=present
  tags:
    - cron
  when: scheduled_production_data_copy

- name: Schedule cron job to copy documents from the production server
  cron: minute=14 name="Copy documents from the production server" job="{{data_dir}}/ecodata/scripts/copyProdDocuments.sh >/dev/null 2>&1" user=root state=present
  tags:
    - cron
  when: scheduled_production_documents_copy

- name: Schedule cron job to automate MERIT downloads
  cron: minute=30 hour=17 weekday=0 name="Scheduled MERIT downloads" job="{{data_dir}}/ecodata/scripts/scheduledDAWEDownloads.sh >/dev/null 2>&1" user="{{ecodata_backup_user}}" state=present
  tags:
    - cron
  when: scheduled_downloads

- name: Prevent ecodatabackup from futher changes to cron from ecodatabackup
  lineinfile:
    path: /etc/cron.allow
    line: "{{ecodata_backup_user}}"
    state: absent
  tags:
    - cron
  when: scheduled_database_backup or scheduled_production_data_copy or scheduled_downloads

# Mongo users and database
- name: Create the ecodata database and user
  mongodb_user:
    login_user: "{{ mongodb_root_username }}"
    login_password: "{{ mongodb_root_password }}"
    login_port: "{{ mongodb_port }}"
    database: "{{ ecodata_database }}"
    name: "{{ ecodata_username }}"
    password: "{{ ecodata_password }}"
    roles:
      - { db: "{{ ecodata_database }}", role: "dbAdmin" }
      - { db: "{{ ecodata_database }}", role: "readWrite" }
  tags:
    - mongodb-org-user


- name: Setup mongo logging to support logrotate
  blockinfile:
    path: /etc/mongod.conf
    insertafter: "systemLog:"
    marker_begin: "BEGIN_logrorate"
    marker_end: "END_logrotate"
    block: |2
        logRotate: reopen
  tags:
    - mongodb-org
    -



- name: Add mongo logrotate config
  template:
    src: logRotate
    dest: /etc/logrotate.d/mongodb
  tags:
    - mongodb-org

- name: Insert replication set name both Server
  blockinfile:
    path: /etc/mongod.conf
    block: |
      replication:
        replSetName: rs0
  notify:
  - restart mongod
  tags: mongodb-org
  when: mongo_replica_enabled

  # Copy the keyfile for authentication
- name: copy security key file to nodes
  copy: src={{ ecodata_local_authentication_keyFile }} dest=/etc/mongodb-keyFile mode=0400
  tags: mongodb-org
  when:  mongo_replica_enabled

# changes access right of the key file for mongo,
- name: change access right of key file
  file: path=/etc/mongodb-keyFile state=file owner=mongodb group=mongodb mode=0400
  when: mongo_replica_enabled

- name: Enable security
  blockinfile:
    path: /etc/mongod.conf
    backup: yes
    marker: '# {mark} Enable mongodb security authorization'
    block: |
      security:
        authorization: enabled
        keyFile: /etc/mongodb-keyFile
  notify:
    - restart mongod
  tags: mongodb-org
  when: mongo_replica_enabled

- name: Stop mongo Service
  service:
    name: mongod
    state: stopped

- name: Start mongod as a service with security
  service:
    name: mongod
    state: started

- name: Updating bind IPs mongodb 3.4
  replace:
    path: /etc/mongod.conf
    regexp: 'bindIp: 127.0.0.1'
    replace: "bindIp: {{ host_ip_address }},127.0.0.1"
  notify:
    - restart mongod
  tags: mongodb-org
  when: "{% if mongo_replication and mongo_version3 %} True {% else %} False {% endif %}"

- name: Stop mongod db server
  service:
    name: mongod
    state: stopped

- name: Start mongod server
  service:
    name: mongod
    state: started

# copying script to create a replica set
- name: copy initrs script only for mongo version 3.4
  template:
    src: initRS.j2
    dest: ./initRS.j2
  when: "{% if mongo_replication and mongo_version3 %} True {% else %} False {% endif %}"

## Initialize the replica set in mongo version 3.4
- name: Initialize the replica set in primary node for mongo version 3.4
  command: mongo --host "{{ mongo_primary_ip }}" --authenticationDatabase "{{ mongodb_root_database | default('admin') }}" -u "{{ mongodb_root_username }}" -p "{{ mongodb_root_password }}" ./initRS.j2
  when: "{% if mongo_replication and mongo_version3 %} True {% else %} False {% endif %}"

# Copy the mongorc to the secondary node. do connect between primary and secondary node without complication
- name: copying mongorc to secondary mongo replica set
  template:
    src: mongorc.js
    dest: /etc/mongorc.js
  when: copy_mongorc_to_secondary_node

- name: Stop mongod db server
  service:
    name: mongod
    state: stopped
  tags: mongodb-org

- name: Start mongod server
  service:
    name: mongod
    state: started
  tags: mongodb-org